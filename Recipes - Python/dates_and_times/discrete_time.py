# Author:   Matt J Williams
#           http://www.mattjw.net
#           mattjw@mattjw.net
# Date:     2015
# License:  MIT License

# Version: 1.0.1
#          10 Feb 2015
#
# Future improvements:
#
# Define a "Discretiser" class. Discretiser(bucket_width, origin_time) would 
# handle a discretisation of time from origin time `origin` with buckets of 
# width `bucket_width`. This would also allow choices of bucket_width that
# do not evenly divide a day.
# The methods would be the same as those already provided in this module.
# In addition, new methods could include `interval_as_discrete` which,
# for a given walltime-to-walltime pair, would return the series of 
# discrete bucket start times that the interval spans.


"""
A collection of tools for managing discrete time representation.

Many tasks involve handling continuous-time data (e.g., data represented
as intervals of time) in a discretised way. This module provides tools for
discretising time (AKA bucketing or binning).

The particular focus of this module is handling real-world time (AKA wallclock
time or or walltime) in a discrete way.

:Daylight savings:
Discretising time can be trick with respect to time zones that observe DST.
A recommended approach is, for any datetimes to be passed to this module,
to first localise to UTC (or any other time zone that does not adjust for DST).
"""


from collections import OrderedDict
from datetime import datetime, timedelta
import fractions


def dt_floor(dt, magnitude='day'):
    """
    Floor a datetime according to a given magntiude.

    For example,
        dt_floor(datetime(2014, 2, 28, 13, 30), magnitude='day'),
    will return the datetime floored to the lowest day:
        datetime(2014, 2, 28, 0, 0).

    Permitted magnitudes are:
        'year', 'month', 'day', 'hour', 'minute', 'second', 'microsecond'

    :Return:
    The floor of `dt` with respect to magnitude `magnitude`.
    """
    mags = ('year', 'month', 'day', 'hour', 'minute', 'second', 'microsecond')
    subs = ( None,   1,       1,     0,      0,        0,        0)

    if magnitude not in mags:
        raise ValueError("Unknown magnitude '%s'; choose from: %s" % (magnitude, ', '.join(mags)))

    replace_from = mags.index(magnitude)
    for indx in xrange(replace_from+1, len(mags)):
        mag = mags[indx]
        sub = subs[indx]
        arg = {mag: sub}
        dt = dt.replace(**arg)
    return dt


def __valid_day_partition(bucket_width):
    """
    Returns true if `bucket_width` evenly partitions a 24-hour period.
    """
    if bucket_width > timedelta(days=1):
        return False

    if (timedelta(days=1).total_seconds() % bucket_width.total_seconds()) != 0:
        return False

    return True


def to_bucket_time(dt, bucket_width):
    """
    'Fix' a continuous time value (datetime `dt`) to its nearest 'fixed' bucket
    time, according to bucket width `bucket_width`.

    The datetime `f` returned by this function is a 'fixed' time that represents
    the discrete-time interval of duration `bucket_width` that contains `dt`;
    i.e.,
        f    <=    dt    <    f + bucket_width.

    :Params:
    `dt`:
        The datetime to be 'fixed'.
    `bucket_width`:
        The bucket width, represented by a timedelta.
    """
    if not __valid_day_partition(bucket_width):
        raise ValueError("'%s' does not evenly partition 24 hours" % bucket_width)

    buck_secs = bucket_width.total_seconds()

    dt_origin = dt_floor(dt, 'day')
    delt_secs = (dt - dt_origin).total_seconds()  #offset into the day

    buck_mult = int(delt_secs // buck_secs)

    fixed_dt = dt_origin + (bucket_width * buck_mult)
    assert fixed_dt <= dt < (fixed_dt + bucket_width)
    return fixed_dt


def generate_bucket_times(min_dt, max_dt, bucket_width):
    """
    Generate a series of equal-duration bucket times. Buckets are separated by
    a duration of `bucket_width`.

    This function carries out a 'fixing' a continuous time value to its
    nearest discretised bucket time. Buckets begin from 00:00, and
    they evenly divide each hour.

    The bucket width should be selected such that it evenly divides a day.

    This function acts as a generator that yields datetimes. For a given 
    datetime `dt` generated by this function, the corresponding bucket 
    represents the half-open interval
        [dt, dt+bucket_width).
    
    The first bucket time `a` returned by this function includes `min_dt`. 
    In other words,
        min_dt  is in interval  [a, a + bucket_width].
    Similarly, the final bucket time `b` is such that
        max_dt  is in interval  [b, b + bucket_width].

    :Params:
    `min_dt`: 
        Datetime. Earliest bucket time. The first bucket will include this time.
    `max_dt`: 
        Datetime. The final bucket will include this time.
    `bucket_width`: 
        Timedelta. Width of bucket.
    
    :Bucket time construction:
    The bucket times begin at 00:00 on `min_dt`. Buckets times at intervals
    separated by `bucket_width` are then generated until the first bucket
    whose interval includes `max_dt` is produced.
    """
    if not __valid_day_partition(bucket_width):
        raise ValueError("'%s' does not evenly partition 24 hours" % bucket_width)

    dt = to_bucket_time(min_dt, bucket_width)
    while dt <= max_dt:
        yield dt
        dt += bucket_width


def discretise(rows, min_dt, max_dt, bucket_width,
               func_start=None, func_end=None, cut_oob=False):
    """
    Discretise a collection of rows representing continuous-time intervals.

    You have a collection of rows (`rows`). Each row represents an interval of
    time, from some start time 'start' (a datetime) to some end time 'end'
    (a datetime). The row contains time-start and time-end items, among other
    elements. The interval represented by a particular row is the half-open
    interval  [time-start, time-end). Discretisation of these rows determines
    which time buckets they belong to, according to the time-start and time-end
    intervals they represent.

    This function carries out discretisation of rows to their corresponding
    buckets.

    The output of this function is an ordered dictionary of bucket times and the
    rows that are allocated to their corresponding buckets; i.e., an
    OrderedDict represents mappings of the form:
        bucket time `t`    ->  list of rows `L`
        datetime               list
    In this case, a particular datetime `t` represents the half-open interval
    [t, t + bucket_width). The list `L` contains all rows in `rows` whose
    duration touches on this interval. The same object from `rows` may therefore
    appear in multiple buckets.
    
    Discretisation is over the time period `min_dt` to `max_dt`. This is assumed
    to be inclusive at `min_dt` and exclusive at `max_dt`.

    The function assumes that each row object encapsulates the time-start and
    time-end in some way. This function is intentionally agnostic to how
    these start and end times are extracted from a row. The arguments
    `func_start` and `func_end` take functions that should retrieve the
    start and end time of a row, respectively.

    For example, if each row in `rows` is a tuple, with start time being held
    in the first element and end time held in the final element, then
    we would use:
        func_start = lambda row: row[0]
        func_end = lambda row: row[-1]
    If not specified, the function will treat each row as a list and use
    row[0] as start time and row[1] as end time.

    :Params:
    rows:
        Sequence of rows (or, more generally, objects), each representing a time
        interval, as well as possibly other attributes.

    min_dt, max_dt:
        Bounds of the time period being discretised. datetime objects.

    bucket_width:
        Width of the discrete time buckets.

    func_start, func_end:
        Functions that return the interval start and interval end time for a 
        row in `rows`. By default, rows are treated as lists/tuples, with first
        element as interval start time and second element as interval end time.

    cut_oob:
        Cut out-of-bounds intervals.
        If True, any intervals (among the `rows`) falling outside (or partially
        outside) the bounds defined by min_dt and max_dt will be cut so only
        their in-bounds periods are retained; i.e., the rows will only be
        placed in buckets during the bounds. Intervals wholly outside the 
        bounds are discarded, since they have no corresponding bucket(s) within
        the bounds.
        If False, rows falling outside the bounds will result in an error.

    :Returns:
    OrderedDict of datetime -> list mappings.
    """
    if not (min_dt <= max_dt):
        raise ValueError("max bound should not precede minimum bound")
        # this also ensures that there is at least one bucket

    if func_start is None:
        func_start = lambda row: row[0]
    if func_end is None:
        func_end = lambda row: row[1]

    buckets = OrderedDict()

    for buck_time in generate_bucket_times(min_dt, max_dt, bucket_width):
        if buck_time == max_dt:
            # break early if the final bucket time happens to fall exactly
            # on `max_dt`; recall that max_dt is exclusive
            break
        buckets[buck_time] = []

    buck_times = buckets.keys()
    buck_lists = buckets.values()

    left_buckbound = buck_times[0]  # lowest allocatable bucket time
    right_buckbound = buck_times[-1]  # highest allocatable bucket time

    for row in rows:
        #
        # extract interval start and end times, fixed to their discretised
        # bucket times
        # the resulting range (i.e., dt1 to dt2) is an inclusive (at both ends)
        # range of bucket times that this row should be allocated to
        dt1_orig = func_start(row)
        dt2_orig = func_end(row)
        if not (dt1_orig <= dt2_orig):
            raise ValueError("Unexpected negative-duration interval: [%s, %s)" % (dt1_orig, dt2_orig))

        dt1 = to_bucket_time(dt1_orig, bucket_width)
        dt2 = to_bucket_time(dt2_orig, bucket_width)
        
        if dt2_orig == dt2:
            # the row's end time falls exactly on a bucket start time.
            # recall that row intervals are half-open; thus row should not#
            # be added to bucket `dt2`, unless the interval is zero-duration
            if dt1_orig != dt2_orig:
                dt2 = dt2 - bucket_width  # shift left by one bucket

        assert dt1 <= dt2

        #
        # slice out-of-bounds intervals
        if cut_oob:
            dt1 = max([dt1, left_buckbound])
            dt2 = min([dt2, right_buckbound])
            if dt2 < dt1:
                # this row's interval is wholly outside the bounds
                continue

        indx1 = buck_times.index(dt1)
        indx2 = buck_times.index(dt2)
        for lst in buck_lists[indx1:indx2+1]:
            lst.append(row)

    return buckets


def discretise_nondisjoint(rows, min_dt, max_dt, bucket_width, increment,
               func_start=None, func_end=None, cut_oob=False):
    """
    A version of `discretise` where overlapping windows are permitted.
    Parameters are the same as `discretise`, with following clarifications
    * `bucket_width` and `increment` are both timedelta objects.
    * `increment` specifies the distance between the start times of two
      consecutive windows.
    * the overlap between two consecutive windows is therefore given by
      `bucket_width - increment`.
    """
    bucksnaps_out = OrderedDict()
    for dt, window in discretise_nondisjoint_generator(rows=rows,
        min_dt=min_dt, max_dt=max_dt, bucket_width=bucket_width,
        increment=increment,
        func_start=func_start, func_end=func_end, cut_oob=cut_oob):
        bucksnaps_out[dt] = window
    return bucksnaps_out    


def discretise_nondisjoint_generator(rows, min_dt, max_dt, bucket_width, increment,
               func_start=None, func_end=None, cut_oob=False):
    """
    Generator version of `discretise_nondisjoint`.
    `discretise_nondisjoint_generator` Yields (datetime, bucket) pairs. Whereas
    `discretise_nondisjoint` returns a concrete OrderedDict.
    The generator version allows more-efficient use of memory.
    """
    assert increment <= bucket_width
    assert increment > timedelta()
    assert bucket_width > timedelta()

    if func_start is None:
        func_start = lambda row: row[0]
    if func_end is None:
        func_end = lambda row: row[1]

    #
    # currently only supports EVENTS (i.e., zero-duration intervals)
    for row in rows:
        assert (func_end(row) - func_start(row)).total_seconds() == 0

    #
    # basic case
    if increment == bucket_width:
        bucksnaps = discretise(rows=rows, min_dt=min_dt, max_dt=max_dt,
            bucket_width=bucket_width, func_start=func_start,
            func_end=func_end, cut_oob=cut_oob)
        for item in bucksnaps.iteritems():
            yield item
        ##return discretise(rows=rows, min_dt=min_dt, max_dt=max_dt,
        ##    bucket_width=bucket_width, func_start=func_start,
        ##    func_end=func_end, cut_oob=cut_oob)

    # for now, we'll do this lazily, and just build on `discretise`
    # this approach is bad news if the gcd of the two times is very small
    # it can mean that we end up with a very long list
    #
    # approach:
    # we generate a bunch of (djsoint) "mini" buckets, which we then aggregate
    # in an overlapping manner

    divisor_secs = fractions.gcd(bucket_width.total_seconds(), increment.total_seconds())
    mini_bucket_width = timedelta(seconds=divisor_secs)
    mini_bucksnaps = discretise(
        rows=rows, min_dt=min_dt, max_dt=max_dt,
        bucket_width=mini_bucket_width,
        func_start=func_start, func_end=func_end, cut_oob=cut_oob)

    num_compose_bucks = bucket_width.total_seconds() // mini_bucket_width.total_seconds()
        # number of mini-windows that need to be aggregated to make a
        # macro window
    assert num_compose_bucks >= 1
    assert num_compose_bucks == int(num_compose_bucks)
    num_compose_bucks = int(num_compose_bucks)

    # Now we have the setup for the next step...
    # aggr_num: number of consecutive buckets we compose
    # mini_bucksnaps: smaller disjoint buckets

    ##bucksnaps_out = OrderedDict()
    items = mini_bucksnaps.items()
    for i in xrange(len(items)-num_compose_bucks):
        dt_start = items[i][0]
        window = []
        for j in xrange(num_compose_bucks):
            window.extend(items[i+j][1])
        yield dt_start, window
        ##bucksnaps_out[dt_start] = window
    ##return bucksnaps_out


def discretise_generic(rows, min_dt, max_dt, bucket_width, increment,
               func_start=None, func_end=None, cut_oob=False):
    """
    A generic and efficient version of `discretise_nondisjoint`. Yields 
    "bucket snapshot" (bucksnaps) pairs. Each pair represents a particular time window:
        window start datetime, list of samples.
    Much more efficient than all other implementations.
        
    CURRENT LIMITATION:
    Does NOT permit "rows" to be an iterator. Must be concrete list. However, with a
    buffer-and-lookahead class, this is a possible improvement.
    
    TO DO:
    This function will replace all discretisation functions.
    """
    assert increment <= bucket_width
    assert increment > timedelta()
    assert bucket_width > timedelta()

    if func_start is None:
        func_start = lambda row: row[0]
    if func_end is None:
        func_end = lambda row: row[1]
        
    assert all(func_start(rows[i]) <= func_start(rows[i+1]) for i in xrange(len(rows) - 1)), "must be sorted"
        # this requires `rows` as concrete list rather than iterator
    
    #
    # currently only supports EVENTS (i.e., zero-duration intervals)
    for row in rows:
        assert (func_end(row) - func_start(row)).total_seconds() == 0
          
    #
    # write as class for simplicity
    class Wrapper(object):
        # i_right = None means "take everything after i_left"
        # i_left = None means nothing left to take"
        # rows[i_left:i_right] are the contents of the window
        # NOT inclusive at i_right
        
        def __init__(self):
            self.win_left = min_dt
            self.win_right = min_dt + bucket_width
            self.N = len(rows)
            if self.N == 0:
                self.i_left = 0
                self.i_right = -1
            else:
                self.i_left = 0
                self.i_right = -1
            self.update_buffer_indices()
        
        def buffer_right_fill(self):
            # fill the buffer with more values from the right
            while True:
                #print 'N=', self.N, '   i_right=', self.i_right
                if (self.i_right+1) >= self.N:
                    break
                elif func_start(rows[self.i_right+1]) < self.win_right:
                    self.i_right += 1
                else:
                    break
                        
        def buffer_left_empty(self):
            # remove values from the left
            while True:
                #print 'N=', self.N, '   i_left=', self.i_left
                if self.i_left >= self.N:
                    break
                elif func_start(rows[self.i_left]) < self.win_left:
                    self.i_left += 1
                else:
                    break
        
        def update_buffer_indices(self):
            # update i_left and i_right to their correction positions
            self.buffer_right_fill()
            self.buffer_left_empty()
            
        def slide_window(self):
            self.win_left += increment
            self.win_right += increment
            self.update_buffer_indices()
            
        def get_bucket(self):
            #print self.i_left, self.i_right
            window = rows[self.i_left:self.i_right+1]
            return (self.win_left, window)

    obj = Wrapper()
    while obj.win_right < max_dt:
        # get the current bucket
        left_dt, buckets = obj.get_bucket()
        
        # validation checks
        if len(buckets) > 0:
            right_dt = left_dt + bucket_width
            assert left_dt <= func_start(buckets[0])
            assert func_start(buckets[-1]) < right_dt, buckets[-1]
        if obj.i_left > 0:
            assert func_start(rows[obj.i_left-1]) < left_dt
        if obj.i_right < (len(rows)-1):
            assert func_start(rows[obj.i_right+1]) >= obj.win_right
        
        # yield
        yield left_dt, buckets
        
        # increment
        obj.slide_window()


if __name__ == "__main__":
    import random

    def pprint_bucks(buckets, width):
        for bucktime, buck in buckets.iteritems():
            i1 = bucktime
            i2 = bucktime + width
            val = [elm[2:]for elm in buck]
            print "%s    [%s, %s)    %s" % (bucktime, i1, i2, val)
    
    def demo(rows, buckets, width):
        print "\n", origin, " to ", fin, " with bucket width ", width

        print "\nRows..."
        for r in rows:
            for d in r[0:2]:
                print str(d) + "  ",
            print r[2:]

        print "\nBuckets..."
        pprint_bucks(buckets, width)
    
    #
    #
    # Example 1
    #
    print "\nEXAMPLE 1 -- RANDOM INTERVALS"
    def random_intervals(dt0, dt1, num):
        dur = dt1 - dt0
        rows = []
        for _ in xrange(N):
            interval = []
            for _ in xrange(2):
                offset = int(random.uniform(0, dur.total_seconds()))
                dt = origin + timedelta(seconds=offset)
                interval.append(dt)
            interval = sorted(interval)
            rows.append(interval)

        return rows

    #
    # Generate
    origin = datetime(2015, 1, 1)
    fin = datetime(2015, 1, 3)
    N = 5
    rows = random_intervals(origin, fin, N)
    rows = [r + [object()] for r in rows]  # append aribtrary object
    
    #
    # Bucketise
    width = timedelta(hours=6)
    buckets = discretise(rows, origin, fin, width)

    #
    # Present
    demo(rows, buckets, width)

    #
    #
    # Example 2
    #
    print "\nEXAMPLE 2 -- DAY-OF-MONTH PRIME RANGES"
    prime_days = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31]

    rows = []
    for indx in xrange(len(prime_days)-1):
        d1 = prime_days[indx]
        d2 = prime_days[indx+1]
        row = [datetime(2015, 1, d1), datetime(2015, 1, d2), object()]
        rows.append(row)

    origin = datetime(2015, 1, 12)
    fin = datetime(2015, 1, 25)

    width = timedelta(hours=24)
    buckets = discretise(rows, origin, fin, width, cut_oob=True)

    demo(rows, buckets, width)

    #
    #
    # Example 3
    #

    print "\nEXAMPLE 3 -- ZERO-DURATION INTERVALS"
    points = [datetime(2015, 2, 3, 0,  0), 
              datetime(2015, 2, 3, 11, 0),
              datetime(2015, 2, 3, 13, 30),
              datetime(2015, 2, 4, 0,  0),  # <- does not appear in bucketing. at non-inclusive end of range
              ]
    rows = [(p, p, object()) for p in points]

    rows.append([datetime(2015, 2, 3, 18, 0), datetime(2015, 2, 3, 20, 0), object()])
    rows.append([datetime(2000, 2, 1), datetime(2020, 9, 3), object()])  # spans whole duration
    rows.append([datetime(2015, 8, 1), datetime(2015, 9, 1), object()])  # wholly outside

    origin = datetime(2015, 2, 3)
    fin = datetime(2015, 2, 4)
    width = timedelta(hours=1)

    buckets = discretise(rows, origin, fin, width, cut_oob=True,
        func_start=lambda r: r[0], func_end=lambda r: r[1])

    demo(rows, buckets, width)

    #
    #
    # Example 4
    #

    print "\nEXAMPLE 4 -- OVERLAPPING WINDOWS"
    points = []
    for add_hours in (range(0, 48, 2) + [92]):
        points.append(datetime(2015, 2, 3, 0, 0) + timedelta(hours=add_hours))
    rows = [(p, p, object()) for p in points]

    origin = datetime(2015, 2, 2, 0, 0)
    fin = datetime(2015, 2, 7, 12, 0)

    width = timedelta(hours=24)
    increment = timedelta(hours=6)

    bucksnaps = discretise_nondisjoint(rows, origin, fin, width, 
        increment=increment,
        cut_oob=True,
        func_start=lambda r: r[0], func_end=lambda r: r[1])

    for dt, rows in bucksnaps.iteritems():
        print dt, "to", dt + width, "            num rows=", len(rows)
        times = [row[0] for row in rows]
        if len(rows) == 0:
            print "\t", len(rows), "rows    "
        else:
            print "\t", len(rows), "rows\t [%s ... %s]" % (min(times), max(times))
        #for row in rows:
        #    #print "\t", row[0], '  ', row[1], '  ', row[2]
            
    #
    #
    # Example 4
    #

    print "\nEXAMPLE 4(b) -- OVERLAPPING WINDOWS (via generic)"
    points = []
    for add_hours in (range(0, 48, 2) + [92]):
        points.append(datetime(2015, 2, 3, 0, 0) + timedelta(hours=add_hours))
    rows = [(p, p, object()) for p in points]

    origin = datetime(2015, 2, 2, 0, 0)
    fin = datetime(2015, 2, 7, 12, 0)

    width = timedelta(hours=24)
    increment = timedelta(hours=6)

    bucksnaps_iter = discretise_generic(rows, origin, fin, width, 
        increment=increment,
        cut_oob=True,
        func_start=lambda r: r[0], func_end=lambda r: r[1])

    for dt, rows in bucksnaps_iter:
        print dt, "to", dt + width, "            num rows=", len(rows)
        times = [row[0] for row in rows]
        if len(rows) == 0:
            print "\t", len(rows), "rows    "
        else:
            print "\t", len(rows), "rows\t [%s ... %s]" % (min(times), max(times))
        #for row in rows:
        #    #print "\t", row[0], '  ', row[1], '  ', row[2]
            
